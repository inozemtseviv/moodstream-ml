# Результаты экспериментов с использованием различных алгоритмов для определения того, понравится пользователю фильм/книга/трек или нет

[Ноутбук с кодом моделей](./MoodStream_Experiments.ipynb)

## Метрика и модели
В качестве метрики я использую RMSE. Метрика Root Mean Squared Error выбрана мной из-за достаточно прозрачной и простой формулы, которую относительно легко объяснить: 
```
RMSE = sqrt(1/n * sum((y_pred - y_true)^2))
```
где `y_pred` - предсказанные значения, `y_true` - фактические значения, `n` - количество примеров.
Таким образом я измеряю отклонение между предсказанными оценками и фактическими.

Тестирование и работу с датасетами осуществляю с помощью [ClearML](https://clear.ml)

Протестированные алгоритмы/модели:
- Коллаборативная фильтрация на основе матричной факторизации (SVDS)
- Метод k-ближайших соседей
- Линейная регрессия
- XGBoost
- CatBoost

---

## Информация о датасетах

### Фильмы
- 750 записей с информацией о фильмах
- 8606070 записей об оценках фильмов
- 258768 пользователей, оставивших оценку

### Книги
- 7473 записей с информацией о книгах
- 102558 записей об оценках книг
- 25468 пользователей, оставивших оценку

### Треки
- 127880 записей с информацией о треках
- 964164 записей об оценках треков
- 6694 пользователей, оставивших оценку

---

## SVDS

Изначально я допустил ошибку в подготовке матрицы и заполнил отсутствующие значения нулями, это фактически означало то, что пользователю элемент не понравился и получил негативную оценку, а не отсутствие оценки вовсе.
Результаты вышли отличные.

/ | Фильмы | Книги | Треки
--- | --- | --- | ---
RMSE | 0.36 | 0.29 | 0.29
Время с. | 103 | 15 | 125


После корректировки ситуация изменилась

/ | Фильмы | Книги | Треки
--- | --- | --- | ---
RMSE | 0.39 | 0.45 | 0.37
Время с. | 103 | 15 | 125


---

## Метод k-ближайших соседей

### С гиперпараметрами по умолчанию
/ | Фильмы | Книги | Треки
--- | --- | --- | ---
RMSE | 0.44 | 0.50 | 0.49
Время с. | 25 | 6 | 8


### С подбором гиперпараметров
Наилучшие параметры, полученные с помощью `GridSearchCV`
```
{'n_neighbors': 7, 'p': 1, 'weights': 'uniform'}
```
/ | Фильмы | Книги | Треки
--- | --- | --- | ---
RMSE | 0.43 | 0.48 | 0.47
Время с. | 33 | 6 | 6

---

## Линейная регрессия

/ | Фильмы | Книги | Треки
--- | --- | --- | ---
RMSE | 0.41 | 0.46 | 0.49
Время с. | 10 | 7 | 6

---

## XGBoost

### С гиперпараметрами по умолчанию
**XGBRegressor**:
/ | Фильмы | Книги | Треки
--- | --- | --- | ---
RMSE | 0.41 | 0.46 | 0.46
Время с. | 52 | 6 | 9

**XGBClassifier**:
/ | Фильмы | Книги | Треки
--- | --- | --- | ---
RMSE | 0.41 | 0.45 | 0.42
Время с. | 50 | 7 | 14


### С подбором гиперпараметров
Наилучшие параметры, полученные с помощью `GridSearchCV`

**XGBRegressor**:
```
{'gamma': 0, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 1000, 'reg_alpha': 1, 'reg_lambda': 1}
```
/ | Фильмы | Книги | Треки
--- | --- | --- | ---
RMSE | 0.41 | 0.44 | 0.42
Время с. | 142 | 15 | 79

---

## CatBoost

### С гиперпараметрами по умолчанию
**CatBoostRegressor**:
/ | Фильмы | Книги | Треки
--- | --- | --- | ---
RMSE | 0.41 | 0.46 | 0.44
Время с. | 146 | 10 | 24

**CatBoostClassifier**:
/ | Фильмы | Книги | Треки
--- | --- | --- | ---
RMSE | 0.47 | 0.55 | 0.60
Время с. | 17 | 6 | 10


### С подбором гиперпараметров
Наилучшие параметры, полученные с помощью `GridSearchCV`

**CatBoostRegressor**:
```
{'depth': 3, 'iterations': 3000, 'learning_rate': 0.07}
```
/ | Фильмы | Книги | Треки
--- | --- | --- | ---
RMSE | 0.41 | 0.46 | 0.44
Время с. | 342 | 17 | 49


| Изменение гиперпараметров не повлияло на результаты, а время обучения модели сильно увеличилось.
---

## Выводы

### С гиперпараметрами по умолчанию
Изучив RMSE для разных датасетов с оценками (фильмы, книги и треки), я делаю вывод, что коллаборативная фильтрация на основе матричной факторизации (SVDS) точнее определяет, понравится элемент пользователю или нет. За ним следуют CatBoost и XGBoost.

![](./assets/moodstream_rmse_base.png)

### С подбором гиперпараметров
Коллаборативная фильтрация на основе матричной факторизации (SVDS) всё так же выдаёт более точный результат, а для XGBoost удалось подобрать такие гиперпараметры, которые позволили обойти CatBoost.

![](./assets/moodstream_rmse_upgraded.png)

---

В результате экспериментов с гиперпараметрами не удалось добиться ощутимого улучшения результатов.
Но в дальнейшем будет добавлена фильтрация по жанрам для повышения релевантности выдачи.

В качестве модели я буду использовать CatBoostRegressor (имеет средние показатели точности) или KNeighborsRegressor (точность ниже, зато высокая скорость обучения).

![](./assets/moodstream_time.png)

